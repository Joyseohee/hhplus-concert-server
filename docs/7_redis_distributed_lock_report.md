# 🎤 콘서트 예약 서비스

## 📝 프로젝트 개요

이 프로젝트는 콘서트 예약 서비스를 위한 대기열 시스템을 설계하는 것입니다.
사용자는 대기열에 등록하고, 좌석을 점유하며, 결제를 통해 좌석 소유권을 획득할 수 있습니다.
이 시스템은 동시성 제어, 상태 기반 흐름 제어, 무결성 보장 등을 고려하여 설계하였습니다.

## 📚 설계 문서
- [요구사항 분석](1_requirements.md)
- [ERD](2_erd.md)
- [시퀀스 다이어그램](3_sequence_diagram.md)
- [상태 다이어그램](4_state_diagram.md)
- [API 명세](https://joyseohee.github.io/hhplus-concert-server)
- [DB 성능 보고서](5_db_report.md)
### 동시성 문제 보고서
- [동시성 이슈 : DB Lock 보고서](6_db_race_condition_report.md)
- [동시성 이슈 : 분산락 보고서](7_redis_distributed_lock_report.md)


## 📄 분산락 적용 보고서 (STEP 11)

## 🚀 STEP 11 목표

* **목표**: DB 락의 한계를 이해하고, Redis 기반의 분산락을 통해 분산 환경에서 발생하는 동시성 문제를 해결
* **핵심 구현 포인트**:

    1. 적절한 **락 키** 선정
    2. 적절한 **락 범위 (작업 단위)** 선정
    3. **트랜잭션 범위**와의 혼용 고려
    4. **통합 테스트**

---

## 🧩 배경

좌석 예약 시스템은 다음과 같은 특성상 동시성 문제가 발생할 수 있습니다. 이에 따른 DB 락의 한계를 이해하고, Redis 기반의 분산락을 적용하여 문제를 해결합니다.

* 단일 자원인 좌석에 **여러 사용자가 동시에 접근**
* **동시에 포인트 충전과 차감**이 일어날 수 있음
* 하나의 트랜잭션 흐름 내에서 **다수의 연속된 상태 변경 작업**
* **RDB 락만으로는** 서버 다중 인스턴스 환경에서 충돌을 완전히 막기 어려움
* 또한 RDB 락은 어떤 작업이든 상관 없이 row나 테이블 단위로 락을 거므로 서버의 **성능 저하**를 유발할 수 있음
* 이를 방지하고자 Redis의 Redisson을 활용해 **분산락을 적용**키로 함

---

## ⚠️ 문제 상황

* A 유저가 유효한 좌석 점유 상태에서 예약 API를 호출했지만, **트랜잭션 완료 전에 점유가 만료**되어 B 유저가 동일 좌석을 점유할 수 있음
* 좌석 만료 처리가 예약 만료 전에 이뤄지지 않도록 **락을 통해 보호**해야 함
* 포인트 잔액 차감이 함께 이루어져야 하므로, **좌석 예약과 금액 차감은 하나의 트랜잭션으로 처리**돼야 함
* 또한 동시에 포인트 충전 요청이 들어올 수 있으므로, **포인트 충전과 차감은 분산락으로 보호**해야 함

---

## 🧪 문제 해결 전략

### ✅ 락 키 선정 기준

* 점유하려는 대상이 단일 자원일 때는 **고유 식별자 기반 키** 사용

    * 예시: `lock:seat:{concertId}:{seatId}`, `lock:user:{userId}:balance`
* 락 키는 식별성과 충돌 방지성, 범용성을 모두 고려

### ✅ 락 범위 (작업 단위) 선정

* 좌석 점유: `concertId + seatId` 단위
* 포인트 충전 및 사용: `userId` 단위

### ✅ 락 적용 대상 메서드
아래는 요청하신 내용을 기반으로 `분산락 적용 전략 정리 표`를 **정확한 동작 방식과 설계 의도를 담아 보완한 버전**입니다. 각 유즈케이스별 분산락 적용 이유와 트랜잭션 범위에 따른 고려 사항을 구체적으로 설명했습니다.

---

### ✅ 분산락 적용 전략 정리

| 유즈케이스                                          | 적용 대상  | 락 키                              | 적용 이유 및 상세 설명                                                                                                                                                                                                                                                            |
| ---------------------------------------------- | ------ | -------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `HoldSeatUseCase.holdSeat`                     | 좌석 점유  | `lock:seat:{concertId}:{seatId}` | - 좌석 점유 시 **중복 점유를 방지**하기 위해 좌석 단위로 분산락을 적용함.<br>- 좌석 점유 정보는 **RDB에 저장**되므로, 이후 단계(예: 예약 확정)에서는 별도로 이 좌석에 대한 락을 유지할 필요 없음.<br>- 즉, 점유 시에만 락을 걸고, 점유 정보는 영속화되므로 다른 트랜잭션에서도 **참조 가능하고 검증 가능**함.<br>- 따라서 `ConfirmReservation` 단계에서는 좌석 락이 **필요하지 않음**.                     |
| `ConfirmReservationUseCase.confirmReservation` | 사용자 잔액 | `lock:user:{userId}:balance`     | - 이 단계에서는 사용자의 잔액을 차감하는 작업이 핵심이며, 동시 충돌이 있을 수 있음.<br>- 따라서 **잔액에 대한 정확한 반영을 보장**하기 위해 사용자 단위로 락을 적용함.<br>- 좌석 점유는 이미 RDB에 저장된 상태이므로, **점유가 중간에 만료되더라도** 이 트랜잭션이 시작된 시점에서 **유효성 검증을 통과했다면 문제가 되지 않음**.<br>- 즉, 점유 만료가 된 이후라도 이 트랜잭션이 유효 점유 상태로 시작되었다면 **락 없이도 예약 확정 가능**. |
| `ChargeBalanceUseCase.chargeBalance`           | 포인트 충전 | `lock:user:{userId}:balance`     | - 사용자의 잔액을 충전하는 작업 역시 동시 요청이 들어올 수 있으므로, 동일한 사용자에 대해 **중복 충전을 방지**하기 위해 락을 적용함.<br>- 사용자 잔액은 수치 연산이기 때문에, 동시에 접근 시 정합성 깨짐 가능성이 높아 **반드시 락이 필요**.                                                                                                                         |

---

### 🔎 보완 설명
* **좌석 점유 시점**에만 `seat` 단위 락을 걸고, 이후 트랜잭션에서는 RDB를 통해 점유 상태를 검증하는 구조는 다음과 같은 장점이 있습니다:
  * **분산락의 범위를 최소화**하여 성능 병목을 줄일 수 있음.
  * 락 해제 후에도 점유 정보가 **RDB에 남아 있으므로**, 확정 예약 단계에서는 해당 정보를 기준으로 검증 가능.
  * 만약 사용자의 점유가 중간에 만료되었더라도, 예약 확정 트랜잭션이 이미 시작되었다면, 그 시점의 유효성을 바탕으로 **문제 없이 처리 가능**.

* 따라서 **트랜잭션의 안정성과 동시성 제어를 모두 확보하면서, 불필요한 락 점유 시간은 줄이는 전략**이라고 할 수 있습니다.
* 그러나 히스토리 추적이 불필요한 좌석 점유가 RDB에 저장되고 있어, 추후 고도화 시 **redis로 Source of Truth를 전환**할 계획이 있습니다.
* 이번 주차에는 분산락 구현에 중점을 두었으므로, 고도화는 관련 주차에 다룰 예정입니다.

### ✅ 트랜잭션 경계와 락 순서

* **트랜잭션보다 먼저 락 획득**
* **락 획득 → 트랜잭션 시작 → 처리 → 커밋/롤백 → 락 해제**
* Redisson의 `tryLock()` 내부에서 AOP로 감싸되, `@Transactional`보다 **먼저 동작하게 설정** (`@Order(HIGHEST_PRECEDENCE)`)

### ✅ 구현 기술

* AOP 기반 커스텀 `@RedisLock` 어노테이션
* RedissonClient의 `RLock.tryLock()`을 기반으로 동기 블로킹 처리
* key 파싱을 위한 `SpELLockKeyParser`

---

## ✅ 테스트/검증

* **Kotest와 latch를 활용한** 동시성 테스트
* 충돌 케이스를 의도적으로 발생시켜 락 획득과 재시도 로직 검증
* **금전적으로 이득이 되는 케이스**의 경우 **재시도** 처리 추가
  * 낙관적 락에 적용되어 있던 로직이 유지되도록 [RedisLockAspect.kt](../src/main/kotlin/kr/hhplus/be/server/infrastructure/lock/aspect/RedisLockAspect.kt)에 재시도 로직 추가
  * 재시도 시 다시 프록시 객체를 통해 메소드가 실행되도록 구현
    * catch 안에서 pjp.proceed()를 호출하지 않고 락 부터 다시 획득하도록 구현
    * transaction이 적용된 메소드의 경우, 트랜잭션 경계가 유지되도록 `@Transactional` 어노테이션을 사용하여 트랜잭션을 관리하며
    * 이 트랜잭션은 락과 분리되어 있음
    * `@Order(HIGHEST_PRECEDENCE)`로 설정하여 트랜잭션보다 먼저 동작하도록 함
  
  ```kotlin
    for (attempt in 0..maxRetries) {
        try {
                return redisLockManager.withLock(key, redisLock.waitTimeMs, redisLock.leaseTimeMs) {
					pjp.proceed() 
                }
			} catch (e: Exception) {
				if (e is LockAcquireException && !redisLock.failFast && attempt < maxRetries) {
					lastError = e

					if (retryDelayMs > 0) Thread.sleep(retryDelayMs)
					continue
				}
				throw e
			}
		}
  ```

---

## 🔍 한계점 및 고려사항

* **락 홀드 시간 설정 주의**: 지나치게 짧으면 중간 작업 실패, 길면 락 점유 시간 과다
* **재시도 로직 신중히 설계**: 낙관적 락 충돌에 대한 재시도는 트랜잭션 부하 증가 가능 -> 금전적으로 이득이 되는 지점에만 최소 한도로 적용

---

## 🧠 결론 및 학습 내용

* 하나의 트랜잭션보다 **하나의 작업 단위**를 기준으로 락을 설계해야 함
* DB 락만으로는 서버 간 자원 점유 보장이 불가
* Redis 기반의 분산락은 서버 수평 확장 환경에서도 **경량/고속 동시성 제어** 가능
* 락 범위, 키 설계, 락 순서의 정합성이 실무 설계의 핵심